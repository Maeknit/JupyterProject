{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Шкалирование признака",
   "id": "6e4ad9c83d6c6a8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T12:53:44.054114Z",
     "start_time": "2025-10-01T12:53:44.042676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "feature = np.array([[-500.5],[-100.1],[0],[100.1],[900.9]])\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ],
   "id": "23bd8dfd06afc26a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Шкалирование - общепринятая задача предобработки в машинном самообучении. <br>\n",
    "Многие алгоритмы исходят из того, что все признаки находятся на одинаковой шкале, как правило от 0 до 1. <br>\n",
    "Существует целый ряд методов шкалирования, один из самых простых - минимаксное шкалирование. <br>\n",
    "В таком шкалировании минимальное и максимальное значения признака используются для шкалирования значений в пределах диапазона <br>\n",
    "$$x'_1 = \\frac{x_1 - min(x)}{max(x)-min(x)}$$"
   ],
   "id": "c98ee5fefc88d9ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Стандартизация признака <br>\n",
    "Требуется преобразовать признак, чтобы он имел среднее значение 0 и стандартное отклонение 1"
   ],
   "id": "7218d3ff83e70f7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T06:15:16.371859Z",
     "start_time": "2025-10-07T06:15:16.342389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import preprocessing\n",
    "x = np.array([[-1000.1],[-200.2],[500.5],[600.6],[9000.9]])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized = scaler.fit_transform(x)\n",
    "standardized"
   ],
   "id": "913a78bd832c1210",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Альтернатива минимаксному шкалированию - шкалирование признаков, при котором они должны быть приближенно стандартно распределены. <br>\n",
    "Для этого используется стандартизация, в ходе которой даннные преобразуются таким образом, что они имеют среднее значение:\n",
    " $$\\bar{x}=0$$ <div align=\"center\">и стандартное отклонение </div> $$\\omega =1 $$\n",
    " <div align=\"center\">  </div>"
   ],
   "id": "bc16ff6265315f84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T06:15:22.657744Z",
     "start_time": "2025-10-07T06:15:22.645241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Среднее:\", round(standardized.mean()))\n",
    "print(\"Стандартное отклонение:\", round(standardized.std()))"
   ],
   "id": "c535de708654e853",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее: 0\n",
      "Стандартное отклонение: 1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T13:07:37.855904Z",
     "start_time": "2025-10-10T13:07:37.768644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "robust_scaler = preprocessing.RobustScaler()\n",
    "robust_scaler.fit_transform(x)"
   ],
   "id": "c02a9ecca31863d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Нормализация наблюдений <br>\n",
    "нормализуем каждое наблюдение (строку данных) так, чтобы его норма стала равна 1"
   ],
   "id": "ef8833f84d3681f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T13:15:41.267732Z",
     "start_time": "2025-10-10T13:15:41.236288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "features = np.array([[0.5, 0.5],\n",
    "                     [1.1, 3.4],\n",
    "                     [1.5, 20.2],\n",
    "                     [1.63, 34.4],\n",
    "                     [10.9, 3.3]])\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "normalizer.transform(features)"
   ],
   "id": "4fdd022abee6f98c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Нормализация убирает влияние \"размера\" (длины текста, яркости изображения и т.п.) оставляя только **пропорции** <br>\n",
    "$$\n",
    "||x||_2=\\sqrt{x^2_1+x^2_2+...+x^2_n}\n",
    "$$\n",
    "Этот тип шкалирования часто используют, когда имеется много эквивалентных признаков (например, в классификации текста, <br>когда каждое слово или группа n-слов является признаком)"
   ],
   "id": "4600df552a6824a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T13:39:45.258418Z",
     "start_time": "2025-10-10T13:39:45.248282Z"
    }
   },
   "cell_type": "code",
   "source": "normalizer.transform(features)",
   "id": "9f4b8eff8ea38ef5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Также существует манхэттенская норма L1\n",
    "$$\n",
    "||x||_1= \\sum_{i=1}^{n} |x_i|\n",
    "$$\n"
   ],
   "id": "20ffe5b464956713"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T13:43:04.748184Z",
     "start_time": "2025-10-10T13:43:04.741601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "features_l1_norm"
   ],
   "id": "425ca506a9ce5bae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Норма L2 рассматривается как расстояние между двумя точками в Нью-Йорке пролетаемой птицей, по прямой.<br>\n",
    "L1 как расстояние пройденного человеком пути по улицам = манхэттенская норма."
   ],
   "id": "1faba783d6db1867"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T13:45:06.891755Z",
     "start_time": "2025-10-10T13:45:06.886092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Сумма значений первого наблюдения:\",\n",
    "      features_l1_norm[0,0]+features_l1_norm[0,1])"
   ],
   "id": "531555446cc42a8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма значений первого наблюдения: 1.0\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18250a280eb11870"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
